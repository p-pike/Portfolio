# Portfolio

## What is in this Github repository ? 
- Churn dataset analysis
- Titanic dataset analysis

The aim of these analysis is to find the model that best fits our problematics. For the titanic dataset we want to predict if a passenger has survived. For the churn dataset we want to predict if a customer is going to leave for the concurrence. These are classification problems.

## How to run ?
To run a Jupyter Notebook you can use either:
- Anaconda (recommended)
- Colab

You must ensure that the python packages are installed with the correct version. For this purpose you can run the first cell of each Notebook.

**Note:** To avoid recomputing I have saved trained models in pickle files. But it is possible to redo the training, by setting the variable redo_training to true. 
